{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10439a1-64d9-43b9-8c55-767a7b39c424",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "This notebook demonstrates the finalized methods of collecting and preprocessing data in a repeatable manner.\n",
    "\n",
    "Everything is built around the `DataCollector` and `Preprocessor` classes, which are collections of helper methods that provide a combined way of collecting all data and preprocessing it for feature selection. The following datasets are collected:\n",
    "\n",
    "\n",
    "Collected datasets:\n",
    "\n",
    "  - rivm: Dutch information on infections and deaths for COVID-19\n",
    "  - stocks: Stock market data\n",
    "  - jhu: Johns Hopkins University for COVID-19 vaccination data\n",
    "  - weather: KNMI Dutch weather service information\n",
    "  - measures: Oxford dataset providing Dutch government measures along with stringency index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09d1ba-ba0a-48e5-ab81-43ad936711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collection import DataCollector, Preprocessor\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from requests import get\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44ce17-2080-4cd7-8896-66f4eed36b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Wikipedia page for the AEX 25 list of companies as a representation of the Dutch Economy\n",
    "\n",
    "wikisection = get(\"https://en.wikipedia.org/w/api.php?action=parse&page=AEX_index&section=7&contentmodel=wikitext&prop=wikitext&format=json\").json()[\"parse\"][\"wikitext\"][\"*\"]\n",
    "wikitable = re.search(r\"cellspacing=2((.|\\s)+)\\}\", wikisection).group(1)\n",
    "compacttable = wikitable.replace(\"|-\\n\",\"\")\n",
    "rows = [_.split(\"||\") for _ in [f\"[{_}\" for _ in \"\".join(compacttable.split(\"\\n\")[2:]).split(\"| [\") if _ != \"\"]]\n",
    "cols = [\n",
    "    \"company\",\n",
    "    \"sector\",\n",
    "    \"ticker\",\n",
    "    \"weighting\"\n",
    "]\n",
    "aex_dict = {c: [] for c in cols}\n",
    "for row in rows:\n",
    "    for i, cell in enumerate(row):\n",
    "        aex_dict[cols[i]] += [cell.strip(\" \")]\n",
    "aex_df = pd.DataFrame({k: v for k, v in aex_dict.items() if k != \"company\"}, index=aex_dict[\"company\"])\n",
    "aex_df[\"ticker\"] = aex_df[\"ticker\"].apply(lambda t: t.split(\"|\")[1])\n",
    "aex_df[\"weighting\"] = aex_df[\"weighting\"].str.replace(\"|\",\"\", regex=False).astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd5c56-d697-4e84-960a-1da80699fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"../data\"\n",
    "LOG_DIR = \"../logs\" \n",
    "START_DATE = \"2019-01-01\"\n",
    "END_DATE = str(datetime.now() - timedelta(days=7))[:10]\n",
    "TICKERS = [t + \".AS\" for t in aex_df.ticker.to_list()]\n",
    "\n",
    "dc = DataCollector(root_dir=ROOT_DIR, log_dir=LOG_DIR, start_date=START_DATE, end_date=END_DATE)\n",
    "datasets = [\n",
    "    \"rivm\",\n",
    "    \"stocks\",\n",
    "    \"jhu\",\n",
    "    \"weather\",\n",
    "    \"measures\"\n",
    "]\n",
    "dfs = {ds: dc.get(dataset=ds) if ds != \"stocks\" else dc.get(dataset=ds, tickers=TICKERS) for ds in datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb95ce5-53f4-4154-9714-2a46482cf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Collected datasets:\")\n",
    "for ds, df in dfs.items():\n",
    "    print(f\"  - {ds}, size: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332a377-dd00-44df-a313-c0f3f2cf1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfs[\"rivm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fa2fc-3f36-4555-bd85-c349fcd519b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfs[\"stocks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9e80d-8235-4e96-994a-e36f0556c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfs[\"jhu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f565ec-dd86-4b53-a98d-356ef4fc4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfs[\"weather\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb0d4c-f2cd-4cc2-a7ac-ae487b2d3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfs[\"measures\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3030bfa-207e-43eb-b31d-6a629e491135",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(root_dir=ROOT_DIR, log_dir=LOG_DIR, datasets=dfs, start_date=START_DATE, end_date=END_DATE)\n",
    "df = preprocessor.preprocess_and_combine()\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
